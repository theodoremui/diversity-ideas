{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import numpy as np\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get embeddings for a single text using text-embedding-3-large model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to generate embeddings for\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: The embedding vector\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=text,\n",
    "        dimensions=1024  # Optional: You can specify 256, 512, or 1024 dimensions\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def get_batch_embeddings(texts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Get embeddings for multiple texts in a single API call.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): List of input texts to generate embeddings for\n",
    "        \n",
    "    Returns:\n",
    "        List[List[float]]: List of embedding vectors\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=texts,\n",
    "        dimensions=1024\n",
    "    )\n",
    "    return [item.embedding for item in response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(embedding1: List[float], embedding2: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two embeddings.\n",
    "    \n",
    "    Args:\n",
    "        embedding1, embedding2 (List[float]): The embedding vectors to compare\n",
    "        \n",
    "    Returns:\n",
    "        float: Cosine similarity score between 0 and 1\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays for easier computation\n",
    "    vec1 = np.array(embedding1)\n",
    "    vec2 = np.array(embedding2)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single embedding length: 1024\n"
     ]
    }
   ],
   "source": [
    "# Single text embedding example\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "embedding = get_embedding(text)\n",
    "print(f\"Single embedding length: {len(embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings: 3\n",
      "Each embedding length: 1024\n"
     ]
    }
   ],
   "source": [
    "# Batch embedding example\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"Pack my box with five dozen liquor jugs\",\n",
    "    \"How vexingly quick daft zebras jump\"\n",
    "]\n",
    "embeddings = get_batch_embeddings(texts)\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "print(f\"Each embedding length: {len(embeddings[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between first two texts: 0.2615\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity between first two texts\n",
    "similarity = calculate_similarity(embeddings[0], embeddings[1])\n",
    "print(f\"Similarity between first two texts: {similarity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
