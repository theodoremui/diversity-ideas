{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infinite Scroll Crawl with Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "class OpinionSpider(scrapy.Spider):\n",
    "    name = \"opinion\"\n",
    "    start_urls = [\"https://dailybruin.com/category/opinion\"]\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Extract initial articles from the page\n",
    "        articles = response.css(\"h3 a::attr(href)\").getall()\n",
    "        for article in articles:\n",
    "            yield {\"url\": article}\n",
    "\n",
    "        # Extract the next page's URL by observing API requests or network activity in the browser\n",
    "        next_page = self.get_next_page_url(response)\n",
    "        if next_page:\n",
    "            yield scrapy.Request(next_page, callback=self.parse_ajax)\n",
    "\n",
    "    def parse_ajax(self, response):\n",
    "        # Parse the AJAX response to extract articles\n",
    "        data = json.loads(response.text)\n",
    "        if 'html' in data:\n",
    "            # Extract articles from the HTML content\n",
    "            html = scrapy.Selector(text=data['html'])\n",
    "            articles = html.css(\"h3 a::attr(href)\").getall()\n",
    "            for article in articles:\n",
    "                yield {\"url\": article}\n",
    "\n",
    "            # If there are more pages, continue crawling\n",
    "            next_page = data.get(\"next\")\n",
    "            if next_page:\n",
    "                yield scrapy.Request(next_page, callback=self.parse_ajax)\n",
    "\n",
    "    def get_next_page_url(self, response):\n",
    "        \"\"\"\n",
    "        Custom logic to extract the next page URL.\n",
    "        Observe the site's API or AJAX structure.\n",
    "        \"\"\"\n",
    "        # Inspect the site to find the pagination AJAX call\n",
    "        api_base = \"https://dailybruin.com/wp-json/dailybruin/v1/posts\"\n",
    "        page_number = 2  # Start from the second page\n",
    "        return f\"{api_base}?page={page_number}&category=opinion\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
